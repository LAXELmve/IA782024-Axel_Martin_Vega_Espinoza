{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76f9a65-0c33-4838-af1f-c8890f13d516",
   "metadata": {},
   "source": [
    "# Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c11dd-0c4e-476c-b0fa-b3ee85d6cfc8",
   "metadata": {},
   "source": [
    "En esta práctica, se debe desarrollar un código capaz de reconocer sentimientos en tiempo real a través de la cámara web. Los objetivos específicos son los siguientes:    \n",
    "\n",
    "## Entrenamiento del Modelo:\n",
    "* Crear un modelo de reconocimiento facial.\n",
    "* Entrenar el modelo utilizando imágenes de personas distintas con expresiones específicas; felicidad, asombro y tristesa.\n",
    "* Asegurarse de que todas las imágenes utilizadas tengan una resolución mínima de 100 x 100 píxeles y una resolución máxima de 150 x 150 píxeles.\n",
    "\n",
    "\n",
    "## Pruebas con Tres Modelos Diferentes:\n",
    "Evaluar el rendimiento del modelo utilizando tres algoritmos distintos:\n",
    "* EigenFaceRecognizer\n",
    "* FisherFaceRecognizer\n",
    "* LBPHFaceRecognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef55a8-44a4-4c6a-bdd0-e911ccbc3f5f",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97cd11-d48b-4888-8a5a-64c218c87e15",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c40652-b3a7-40f1-ada7-9e28853ed196",
   "metadata": {},
   "source": [
    "Se importan las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d730b7-3e46-4208-b0aa-6f506b07dede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdb45f-ba7a-4de7-970a-60af363a756a",
   "metadata": {},
   "source": [
    "El siguiente código se encarga de tomar capturas de los rostros que el sistema detecte mediante la cámara web con la ayuda de un archivo ya entrenado de tipo HaarCascade para identificar los rostros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8989959-6660-4f8d-ab87-8aac2433cbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usuario = 'axel'\n",
    "rostro = cv.CascadeClassifier('./haarcascade/haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3373b-f646-4f76-8c8d-f86a415e6ca7",
   "metadata": {},
   "source": [
    "Cada bloque de código se encarga de almacenar una emoción específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48520e14-35db-45da-adfd-e90a2364b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 5)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        #frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y+h, x:x+w]\n",
    "        #cv.imshow('rostros', frame)\n",
    "        frame2 = cv.resize(frame2, (100, 100))\n",
    "        cv.imshow('rostros', frame2)\n",
    "        cv.imwrite('D:/Users/axelv/Images/caras/'+ usuario +'/feliz/'+ usuario +'_f'+str(i)+'.png', frame2)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6037ffa8-7716-4f72-9745-cdb0793bc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 5)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        #frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y+h, x:x+w]\n",
    "        #cv.imshow('rostros', frame)\n",
    "        frame2 = cv.resize(frame2, (100, 100))\n",
    "        cv.imshow('rostros', frame2)\n",
    "        cv.imwrite('D:/Users/axelv/Images/caras/'+ usuario +'/triste/'+ usuario +'_t'+str(i)+'.png', frame2)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d695896-8a59-42b8-a43c-b44ff0daed17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 5)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        #frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y+h, x:x+w]\n",
    "        #cv.imshow('rostros', frame)\n",
    "        frame2 = cv.resize(frame2, (100, 100))\n",
    "        cv.imshow('rostros', frame2)\n",
    "        cv.imwrite('D:/Users/axelv/Images/caras/'+ usuario +'/sorprendido/'+ usuario +'_s'+str(i)+'.png', frame2)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f56af-6371-47a5-9d88-a7c6903611bc",
   "metadata": {},
   "source": [
    "En el siguiente código se inicializan las variables necesarias para ubicar y almacenar tanto las imágenes como las etiquetas respectivas para cada emoción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffb0de5-e74c-45f7-9344-e4e332f09046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feliz', 'sorprendido', 'triste']\n",
      "545\n"
     ]
    }
   ],
   "source": [
    "dataSet = './emociones'\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "print(np.count_nonzero(np.array(labels)==0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35cd5a-64a3-4d3d-a9bf-f4e584db070c",
   "metadata": {},
   "source": [
    "## Eigenface "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49987c74-5725-4687-b4b8-eae417c2ce7b",
   "metadata": {},
   "source": [
    "Este bloque de código se encarga de crear un xml de entrenamiento para detectar las emociónes mediante el modelo Eigenface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d72c9ee-d1d5-46b7-a952-e5e4a230c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('./modelos/EmocionesEigenface.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652523c0-5241-4023-9f63-a4676c2ad0af",
   "metadata": {},
   "source": [
    "## Fisherfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990e36c-4026-4db2-be93-cb3303539908",
   "metadata": {},
   "source": [
    "Este bloque de código se encarga de crear un xml de entrenamiento para detectar las emociónes mediante el modelo Fisherfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8c7724-ddb4-417c-9df1-12af029f994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.FisherFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('./modelos/EmocionesFisherface.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6284b819-c10c-43dd-a4a5-d7dd93d49871",
   "metadata": {},
   "source": [
    "## LBPH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c4d5d-1cfb-47e2-bdbb-377f0be75d90",
   "metadata": {},
   "source": [
    "Este bloque de código se encarga de crear un xml de entrenamiento para detectar las emociónes mediante el modelo LBPH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd5b89f-e836-431f-8c8f-52fcfdffbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('./modelos/EmocionesLBPH.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8f753-845d-4e61-b9a2-bf059f5db603",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689fed1-0569-47a4-b23e-f3f9f427e4c0",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15e96d-f646-4562-b784-13a2570e910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Para las pruebas de funcionamiento se desarrollaron tres bloques de código para trabajar con cada uno de los modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a1964-343c-450f-8cc8-22e219b54780",
   "metadata": {},
   "source": [
    "## Eigenface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260a9656-7045-460c-aedd-d169038f502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.read('./modelos/EmocionesEigenface.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('./haarcascade/haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        #cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        if result[1] > 2800:\n",
    "            # el arreglo result es algo así: [etiqueta: 1, valor: 3000]\n",
    "            cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        else:\n",
    "            cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv.imshow('Emociones Eigenface', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d190ac58-d45b-4085-911a-ef4ccf445316",
   "metadata": {},
   "source": [
    "## Fisherfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8846d749-5d82-4958-ab42-e15b243dc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.FisherFaceRecognizer_create()\n",
    "faceRecognizer.read('./modelos/EmocionesFisherface.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('./haarcascade/haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        # cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        if result[1] > 2:\n",
    "            # el arreglo result es algo así: [etiqueta: 1, valor: 3000]\n",
    "            cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        else:\n",
    "            cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv.imshow('Emociones Fisherface', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85142315-0b15-44aa-98ce-23bcf1245c10",
   "metadata": {},
   "source": [
    "## LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaff7e18-17bf-4b81-9a0e-ca4832cde9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read('./modelos/EmocionesLBPH.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('./haarcascade/haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        # cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        if result[1] > 80:\n",
    "            # el arreglo result es algo así: [etiqueta: 1, valor: 3000]\n",
    "            cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        else:\n",
    "            cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv.imshow('Emociones LBPH', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94d0d4-843c-45cb-a962-3df84866a374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1f7be-c5d6-4bbe-bc1d-d2bf9ae1e990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
